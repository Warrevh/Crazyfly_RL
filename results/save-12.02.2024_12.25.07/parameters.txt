PARAMETERS


initial_xyzs: [[4.5 3.5 0.2]]
ctrl_freq: 240
Target_pos: [2.5 2.  0.2]
episode_length: 40
Learning_rate: 0.0005
Learning_rate_decay: -0.005
Target_reward: 100000
Rew_distrav_fact: 0
Rew_disway_fact: 0.1
Rew_step_fact: 0
Rew_tardis_fact: 1
eval_freq: 5
position: True
velocity: True
rpy: False
ang_v: True
prev_act: False
Total_timesteps: 30000000
train_freq: 120
Reward_Function: (-self.Rew_distrav_fact*(np.linalg.norm(self.reward_state[0:2]-prev_state[0:2]))-self.Rew_disway_fact*(np.linalg.norm(self.TARGET_POS[0:2]-self.reward_state[0:2])**4)-self.Rew_step_fact*1 +self.Rew_tardis_fact*(prev_tar_dis-self.target_dis))
